{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luke Rausch\n",
    "\n",
    "CS-119 Quiz 2\n",
    "\n",
    "Due: 17Sep2024\n",
    "\n",
    "# Question 1\n",
    "a. The man pwd command displays the information for the pwd command. Upon further research man stands for manual, and pwd stands for print working directory. When trying other commands with man such as \"man ls\" we get a similar output as \"man pwd\" but simply correlating to ls. The manual also displays some additional commands that can be used.\n",
    "\n",
    "b. I sort of think of piping like setting a variable. The output of one command is input into the next command, like if I said n = 10 and then used n in the next line of code. The analogy breaks down the more I think about it, but that's how piping initially made sense to me. \n",
    "\n",
    "c. stdin - standard input - or where the commands get the input data from. In the case of this hw assignment the stdin is the Washington Post dataset.\n",
    "\n",
    "   stdout - standard output - where the commands send the output. In this case it is the terminal (even though I am accessing the terminal through vscode/jupyter notebook).\n",
    "   \n",
    "   stderr - standard error - where the commands send the error messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "Decompress the file with zcat, pipe to the next command which says display just the first row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gzip: /mnt/c/Users/luker_6pkd98w/OneDrive/Documents/Tufts/CS-119.gz: No such file or directory\n",
      "gzip:  Big Data/hw/hw2/arcos_all_washpost.tsv.gz: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!zcat /mnt/c/Users/luker_6pkd98w/OneDrive/Documents/Tufts/CS-119\\ Big\\ Data/hw/hw2/arcos_all_washpost.tsv.gz | head -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "Decompress the file with zcat. Skip the first line in the file (the headers). Word count (wc) -1 to count the rows in the input from previous command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178598026\n"
     ]
    }
   ],
   "source": [
    "!zcat /mnt/c/Users/luker_6pkd98w/OneDrive/Documents/Tufts/CS-119\\ Big\\ Data/hw/hw2/arcos_all_washpost.tsv.gz | tail -n +2 | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HYDROCODONE\n",
      "OXYCODONE\n"
     ]
    }
   ],
   "source": [
    "!zcat /mnt/c/Users/luker_6pkd98w/OneDrive/Documents/Tufts/CS-119\\ Big\\ Data/hw/hw2/arcos_all_washpost.tsv.gz | awk -F'\\t' 'NR==1{for(i=1;i<=NF;i++) if($i==\"DRUG_NAME\") col=i} NR>1{print $col}' | sort | uniq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wanted the column index for TRANSACTION_DATE, so I found that here first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gzip: 31\n",
      "stdout: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!zcat /mnt/c/Users/luker_6pkd98w/OneDrive/Documents/Tufts/CS-119\\ Big\\ Data/hw/hw2/arcos_all_washpost.tsv.gz | head -1 | awk -F'\\t' '{for(i=1;i<=NF;i++) if($i==\"TRANSACTION_DATE\") print i}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First shuffled the dataset, grabbed a subset of 7500 points and wrote to subset.tsv.\n",
    "Next, took a substring from the 31st column (TRANSACTION_DATE). The substring should contain only the year portion of the date.\n",
    "Then the substrings are sorted (probably unnecessary upon reflection) and unique occurences are counted up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    887 2006\n",
      "    991 2007\n",
      "   1028 2008\n",
      "   1096 2009\n",
      "   1134 2010\n",
      "   1184 2011\n",
      "   1180 2012\n"
     ]
    }
   ],
   "source": [
    "!zcat /mnt/c/Users/luker_6pkd98w/OneDrive/Documents/Tufts/CS-119\\ Big\\ Data/hw/hw2/arcos_all_washpost.tsv.gz | shuf -n 7500 > subset.tsv\n",
    "!awk -F'\\t' '{print substr($31, 5, 4)}' subset.tsv | sort | uniq -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I calculated the total estimated occurences for each year across the whole dataset. I know I probably should have done this with Linux commands. My commands were taking a long time to run and I got frustrated continually waiting and getting the wrong result, so I just took the outputs from above where necessary and did the math with Python. That is not in the spirit of the question, so I apologize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006: 21122193\n",
      "2007: 23598753\n",
      "2008: 24479836\n",
      "2009: 26099125\n",
      "2010: 27004022\n",
      "2011: 28194675\n",
      "2012: 28099423\n"
     ]
    }
   ],
   "source": [
    "sampled_counts = {\n",
    "    '2006': 887,\n",
    "    '2007': 991,\n",
    "    '2008': 1028,\n",
    "    '2009': 1096,\n",
    "    '2010': 1134,\n",
    "    '2011': 1184,\n",
    "    '2012': 1180\n",
    "}\n",
    "\n",
    "total_count = 178598026\n",
    "sampled_size = 7500\n",
    "\n",
    "estimates = {}\n",
    "\n",
    "for year, count in sampled_counts.items():\n",
    "    estimates[year] = round(count / sampled_size * total_count)\n",
    "\n",
    "for year, estimate in estimates.items():\n",
    "    print(f\"{year}: {estimate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4000 rows extracted, using similar substring technique as previous problemm, but only selecting rows when the result is 2012. File is then saved locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gzip: stdout: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!zcat /mnt/c/Users/luker_6pkd98w/OneDrive/Documents/Tufts/CS-119\\ Big\\ Data/hw/hw2/arcos_all_washpost.tsv.gz | awk -F'\\t' '{if (substr($31, 5, 4) == \"2012\") print}' | head -n 4000 > /mnt/c/Users/luker_6pkd98w/OneDrive/Documents/Tufts/CS-119\\ Big\\ Data/hw/hw2/arcos_2012.tsv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the start of this quiz I didn't want to do the assignment in the terminal, as I wanted an easier way to format and show my work. I regret that now and wish I had just used the terminal. It would have been easier for me to understand the assignment and what is actually going on rather than fighting to figure out how to get the whole VSCode/jupyter/linux terminal connections working. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
